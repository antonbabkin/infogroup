{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move YTS data to BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Move in and out\n",
    "- ExpStart and NewStart\n",
    "\n",
    "- upload csv -> gcs -> bq using API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs\n",
    "\n",
    "[BQ Pricing guide](https://cloud.google.com/bigquery/pricing)\n",
    "\n",
    "Storage: \\$0.02 per 1 GB per month.  \n",
    "Query: \\$5 per 1 TB, first TB per month free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "Resources: [project](https://console.cloud.google.com/home/dashboard?project=info-group-162919) \n",
    "[storage](https://console.cloud.google.com/storage/browser?project=info-group-162919)\n",
    "[bigquery](https://bigquery.cloud.google.com/dataset/info-group-162919:yts?pli=1)\n",
    "\n",
    "[Variable definitions](https://docs.google.com/document/d/139zMJgQjDEwZLR40CiOMZIecklTKQ9Z4_pxWN7w9JZ0/edit)\n",
    "\n",
    "Help:\n",
    "[bq](https://cloud.google.com/bigquery/docs/how-to)\n",
    "[bq sql](https://cloud.google.com/bigquery/docs/reference/standard-sql/)\n",
    "[bq python api](https://googlecloudplatform.github.io/google-cloud-python/latest/bigquery/usage.html)\n",
    "\n",
    "speed up queries: [bq partitions](https://cloud.google.com/bigquery/docs/partitioned-tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greg's files have `\\r` for newlines, `csv` module can recognize it, but `bash` tools usually don't. To view them, need to convert newline characters first:\n",
    "```bash\n",
    "tr '\\r' '\\n' < YTS2_3_2.csv > YTS2_3_2_conv.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cells have vetrical tabs in them (`\\v` or `^K`). Extract all rows that have such cells:\n",
    "```bash\n",
    "head -n1 YTS2_3_2_conv.csv > YTS2_3_2_vtab.csv\n",
    "grep -P '\\v' YTS2_3_2_conv.csv >> YTS2_3_2_vtab.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T23:48:12.478986Z",
     "start_time": "2017-11-20T23:48:06.135827Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, json\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from google.cloud import storage, bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T23:48:13.389927Z",
     "start_time": "2017-11-20T23:48:13.358784Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BQ parameters\n",
    "client = bigquery.Client()\n",
    "wide_table_ref = client.dataset('yts').table('wide')\n",
    "long_table_ref = client.dataset('yts').table('long')\n",
    "lag_table_ref = client.dataset('yts').table('lag')\n",
    "fips_table_ref = client.dataset('yts').table('fips')\n",
    "state_table_ref = client.dataset('yts').table('state')\n",
    "wide_table_path = wide_table_ref.dataset_id + '.' + wide_table_ref.table_id\n",
    "long_table_path = long_table_ref.dataset_id + '.' + long_table_ref.table_id\n",
    "lag_table_path = lag_table_ref.dataset_id + '.' + lag_table_ref.table_id\n",
    "fips_table_path = fips_table_ref.dataset_id + '.' + fips_table_ref.table_id\n",
    "state_table_path = state_table_ref.dataset_id + '.' + state_table_ref.table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T23:48:14.726114Z",
     "start_time": "2017-11-20T23:48:14.718615Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_report(query_job, start_time):\n",
    "    elapsed_time = time() - start_time\n",
    "    mb_proc = query_job.total_bytes_processed / (1 << 20)\n",
    "    mb_bill = query_job.total_bytes_billed / (1 << 20)\n",
    "    tb_bill = mb_bill / (1 << 20)\n",
    "    cost = 5 * tb_bill \n",
    "    print('Query finished in %d seconds. Processed %d MB, billed %d MB, cost $%.2f.' % (elapsed_time, mb_proc, mb_bill, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T16:28:54.032774Z",
     "start_time": "2017-11-16T16:28:54.027223Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_filename = 'YTS10_23_17All.csv'\n",
    "corrected_filename = 'YTS10_23_17All_corrected.csv'\n",
    "corrections_filename = 'YTS10_23_17All_corrections.csv'\n",
    "bq_schema_filename = 'bq_schema.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct raw data\n",
    "Keep only last value in fields with vertical tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-15T22:20:19.379Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(raw_filename, mode='r', errors='ignore', newline='') as fp_in, \\\n",
    "    open(corrected_filename, mode='w', newline='') as fp_out, \\\n",
    "    open(corrections_filename, mode='w', newline='') as fp_cor:\n",
    "\n",
    "    reader = csv.reader(fp_in)\n",
    "    writer_out = csv.writer(fp_out)\n",
    "    writer_cor = csv.writer(fp_cor)\n",
    "    \n",
    "    # header\n",
    "    field_names_in = next(reader)\n",
    "    _ = writer_out.writerow(field_names_in)\n",
    "    field_names_cor = ['line_number', 'column_number', 'abi', 'field_name', 'old_value', 'new_value']\n",
    "    _ = writer_cor.writerow(field_names_cor)\n",
    "    \n",
    "    # data rows\n",
    "    line_i = 2\n",
    "    for row_in in reader:\n",
    "        row_out = []\n",
    "        for col_i, value in enumerate(row_in):\n",
    "            value_split = value.split('\\v')\n",
    "            new_value = value_split[-1]\n",
    "            row_out.append(new_value)\n",
    "            if len(value_split) > 1:\n",
    "                abi = row_in[0]\n",
    "                row_cor = [line_i, col_i, abi, field_names_in[col_i], value, new_value]\n",
    "                _ = writer_cor.writerow(row_cor)\n",
    "        _ = writer_out.writerow(row_out)\n",
    "        \n",
    "        line_i += 1\n",
    "        if line_i % 1000000 == 0: print(line_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T16:51:42.310468Z",
     "start_time": "2017-11-16T16:51:30.777736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Latitude      7732297\n",
       "Longitude     7732297\n",
       "HQFIPS2016          1\n",
       "Name: field_name, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what fields where corrected\n",
    "df = pd.read_csv(corrections_filename, dtype='object', usecols=['field_name'])\n",
    "df.field_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There might be issues with some values, auto-detected schema sets ABI to integer and fails:\n",
    "```\n",
    "Errors:\n",
    "gs://ig-anton/YTS10_23_17All_corrected.csv: CSV table encountered too many errors, giving up. Rows: 60519; errors: 1. (error code: invalid)\n",
    "gs://ig-anton/YTS10_23_17All_corrected.csv: Could not parse 'IG4775007' as int for field ABI (position 0) starting at location 22211225052 (error code: invalid)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload corrected CSV to GCS\n",
    "```bash\n",
    "gsutil -m cp YTS10_23_17All_corrections.csv gs://ig-anton\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV from GCS into BQ\n",
    "Via Web UI, copy-paste JSON schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-16T16:29:24.261608Z",
     "start_time": "2017-11-16T16:29:24.195138Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare BQ schema\n",
    "df = pd.read_csv(corrected_filename, nrows=100, dtype='object')\n",
    "\n",
    "bq_schema = []\n",
    "for field_name in df:\n",
    "    if field_name == 'FirstYear' or field_name == 'LastYear' or field_name[:3] == 'Emp' or field_name[:5] == 'Sales':\n",
    "        bq_type = 'INTEGER'\n",
    "    elif field_name == 'Latitude' or field_name == 'Longitude':\n",
    "        bq_type = 'FLOAT'\n",
    "    else:\n",
    "        bq_type = 'STRING'\n",
    "    bq_field = {'name': field_name, 'type': bq_type}\n",
    "    bq_schema.append(bq_field)\n",
    "\n",
    "with open(bq_schema_filename, 'w') as fp:\n",
    "    json.dump(bq_schema, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert BQ table from wide to long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T23:49:28.478320Z",
     "start_time": "2017-11-20T23:48:28.677593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query finished in 59 seconds. Processed 10517 MB, billed 10518 MB, cost $0.05.\n"
     ]
    }
   ],
   "source": [
    "# construct query: union of tables for every year\n",
    "query_select_year = '''\n",
    "SELECT\n",
    "  {y} AS year,\n",
    "  ABI AS abi,\n",
    "  Emp{y} AS emp,\n",
    "  Sales{y} AS sales,\n",
    "  FIPS{y} AS fips,\n",
    "  NAICS{y} AS naics,\n",
    "  {startup} as startup\n",
    "FROM\n",
    "  `{table}`\n",
    "WHERE\n",
    "  Emp{y} IS NOT NULL\n",
    "'''\n",
    "\n",
    "query_list = []\n",
    "for y in range(1997, 2017):\n",
    "    startup = 'Startup%d' % y if y > 1997 else 'null'\n",
    "    query_list.append(query_select_year.format(y=y, table=wide_table_path, startup=startup))\n",
    "query = '\\nUNION ALL\\n'.join(query_list)\n",
    "\n",
    "# configure job\n",
    "job_id = 'yts_wide_to_long_%d' % time()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.destination = long_table_ref\n",
    "\n",
    "# start job\n",
    "t = time()\n",
    "query_job = client.query(query, job_config=job_config, job_id=job_id)\n",
    "_ = query_job.result()\n",
    "\n",
    "query_report(query_job, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare lagged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T18:57:20.675516Z",
     "start_time": "2017-11-20T18:55:44.118989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query finished in 96 seconds. Processed 15136 MB, billed 15137 MB, cost $0.07.\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "  * \n",
    "  EXCEPT (year_preceding)\n",
    "  REPLACE (\n",
    "    IF(year_preceding = year - 1, emp_lag, null) AS emp_lag\n",
    "  ),\n",
    "  IF(year_preceding = year - 1, emp - emp_lag, null) AS emp_change\n",
    "FROM (\n",
    "  SELECT\n",
    "    abi,\n",
    "    year,\n",
    "    fips,\n",
    "    emp,\n",
    "    sales,\n",
    "    naics,\n",
    "    startup,\n",
    "    LAG(emp) OVER (PARTITION BY abi ORDER BY year) AS emp_lag,\n",
    "    LAG(FALSE, 1, TRUE) OVER (PARTITION BY abi ORDER BY year) AS birth,\n",
    "    LEAD(FALSE, 1, TRUE) OVER (PARTITION BY abi ORDER BY year) AS death,\n",
    "    LAG(year) OVER (PARTITION BY abi ORDER BY year) AS year_preceding,\n",
    "    CASE\n",
    "      WHEN emp = 1 THEN 1\n",
    "      WHEN emp BETWEEN 2 AND 9 THEN 2\n",
    "      WHEN emp BETWEEN 10 AND 99 THEN 10\n",
    "      WHEN emp BETWEEN 100 AND 499 THEN 100\n",
    "      WHEN emp >= 500 THEN 500\n",
    "      ELSE -1\n",
    "    END AS size\n",
    "  FROM\n",
    "    `{table}`\n",
    ");\n",
    "'''\n",
    "query = query.format(table=long_table_path)\n",
    "\n",
    "# prepare job\n",
    "job_id = 'yts_long_to_lag_%d' % time()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.destination = lag_table_ref\n",
    "\n",
    "# start job\n",
    "t = time()\n",
    "query_job = client.query(query, job_config=job_config, job_id=job_id)\n",
    "_ = query_job.result()\n",
    "\n",
    "query_report(query_job, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute aggregate stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate on FIPS level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T19:37:08.730545Z",
     "start_time": "2017-11-20T19:36:47.861313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query finished in 20 seconds. Processed 13632 MB, billed 13633 MB, cost $0.07.\n"
     ]
    }
   ],
   "source": [
    "# continuation and birth\n",
    "query_cont_bir = '''\n",
    "SELECT\n",
    "  fips,\n",
    "  year,\n",
    "  size,\n",
    "  COUNT(*) AS est,\n",
    "  SUM(emp) AS emp,\n",
    "  SUM(sales) AS sales,\n",
    "  COUNTIF(birth) AS est_birth,\n",
    "  COUNTIF(NOT birth AND emp_change > 0) AS est_expand,\n",
    "  COUNTIF(NOT birth AND emp_change < 0) AS est_contract,\n",
    "  SUM(IF(birth, emp, 0)) AS emp_birth,\n",
    "  SUM(IF(emp_change > 0, emp_change, 0)) AS emp_expand,\n",
    "  SUM(IF(emp_change < 0, -emp_change, 0)) AS emp_contract\n",
    "FROM\n",
    "  {table}\n",
    "GROUP BY\n",
    "  fips, year, size\n",
    "'''.format(table=lag_table_path)\n",
    "\n",
    "# death\n",
    "query_dea = '''\n",
    "SELECT\n",
    "  fips,\n",
    "  year + 1 AS year,\n",
    "  size,\n",
    "  COUNT(*) AS est_death,\n",
    "  SUM(emp) AS emp_death\n",
    "FROM\n",
    "  {table}\n",
    "WHERE\n",
    "  death\n",
    "GROUP BY\n",
    "  fips, year, size\n",
    "'''.format(table=lag_table_path)\n",
    "\n",
    "# join continuation, birth and death into one table\n",
    "query_join = '''\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ({q_cont_bir}) FULL OUTER JOIN ({q_dea}) USING(fips, year, size)\n",
    "'''.format(q_cont_bir=query_cont_bir, q_dea=query_dea)\n",
    "\n",
    "# overwrite with zero null years: typically high size deaths\n",
    "# overwrite with null undefined years: backward-looking variables in 1997 and forward-looking variables in 2016\n",
    "query = '''\n",
    "SELECT\n",
    "  *\n",
    "  REPLACE (\n",
    "    IF(year = 1997, NULL, IF(est_birth is NULL, 0, est_birth)) AS est_birth,\n",
    "    IF(year = 1997, NULL, IF(est_expand is NULL, 0, est_expand)) AS est_expand,\n",
    "    IF(year = 1997, NULL, IF(est_contract is NULL, 0, est_contract)) AS est_contract,\n",
    "    IF(year = 1997, NULL, IF(emp_birth is NULL, 0, emp_birth)) AS emp_birth,\n",
    "    IF(year = 1997, NULL, IF(emp_expand is NULL, 0, emp_expand)) AS emp_expand,\n",
    "    IF(year = 1997, NULL, IF(emp_contract is NULL, 0, emp_contract)) AS emp_contract,\n",
    "    IF(year = 1997, NULL, IF(est_death is NULL, 0, est_death)) AS est_death,\n",
    "    IF(year = 1997, NULL, IF(emp_death is NULL, 0, emp_death)) AS emp_death\n",
    "  )\n",
    "FROM\n",
    "  ({q_join})\n",
    "WHERE\n",
    "  year != 2017 AND fips is not NULL\n",
    "ORDER BY\n",
    "  fips, year, size\n",
    "'''.format(q_join=query_join)\n",
    "\n",
    "# prepare job\n",
    "job_id = 'yts_agg_fips_%d' % time()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.destination = fips_table_ref\n",
    "\n",
    "# start job\n",
    "t = time()\n",
    "query_job = client.query(query, job_config=job_config, job_id=job_id)\n",
    "_ = query_job.result()\n",
    "\n",
    "query_report(query_job, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate on state level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T19:45:19.987646Z",
     "start_time": "2017-11-20T19:45:18.671457Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get state codes\n",
    "df = pd.read_csv('https://www2.census.gov/geo/docs/reference/state.txt', delimiter='|', dtype='object')\n",
    "state_codes = {\n",
    "    'numcode_to_strcode': dict(zip(df.STATE, df.STUSAB)),\n",
    "    'numcode_to_name': dict(zip(df.STATE, df.STATE_NAME)),\n",
    "    'strcode_to_name': dict(zip(df.STUSAB, df.STATE_NAME))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T19:47:10.956212Z",
     "start_time": "2017-11-20T19:47:08.972222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query finished in 1 seconds. Processed 31 MB, billed 32 MB, cost $0.00.\n"
     ]
    }
   ],
   "source": [
    "# aggregate from FIPS by 2-digit state code\n",
    "query_state_code = '''\n",
    "SELECT\n",
    "  SUBSTR(fips, 1, 2) as state_code,\n",
    "  year,\n",
    "  size,\n",
    "  SUM(est) AS est,\n",
    "  SUM(emp) AS emp,\n",
    "  SUM(sales) AS sales,\n",
    "  SUM(est_birth) AS est_birth,\n",
    "  SUM(est_expand) AS est_expand,\n",
    "  SUM(est_contract) AS est_contract,\n",
    "  SUM(est_death) AS est_death,\n",
    "  SUM(emp_birth) AS emp_birth,\n",
    "  SUM(emp_contract) AS emp_contract,\n",
    "  SUM(emp_expand) AS emp_expand,\n",
    "  SUM(emp_death) AS emp_death\n",
    "FROM\n",
    "  `{table}`\n",
    "GROUP BY\n",
    "  state_code, year, size\n",
    "'''.format(table=fips_table_path)\n",
    "\n",
    "# add 2-letter state code\n",
    "query_code_expr = 'CASE state_code\\n'\n",
    "for code_pair in state_codes['numcode_to_strcode'].items():\n",
    "    query_code_expr += '  WHEN \"%s\" THEN \"%s\"\\n' % code_pair\n",
    "query_code_expr += '  ELSE \"N/A\"\\nEND'\n",
    "\n",
    "query = '''\n",
    "SELECT\n",
    "  {code_expr} AS state,\n",
    "  *\n",
    "FROM\n",
    "  ({q_state_code})\n",
    "ORDER BY\n",
    "  state, year, size\n",
    "'''.format(code_expr=query_code_expr, q_state_code=query_state_code)\n",
    "\n",
    "# prepare job\n",
    "job_id = 'yts_agg_state_%d' % time()\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "job_config.destination = state_table_ref\n",
    "\n",
    "# start job\n",
    "t = time()\n",
    "query_job = client.query(query, job_config=job_config, job_id=job_id)\n",
    "_ = query_job.result()\n",
    "\n",
    "query_report(query_job, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query results\n",
    "![Results layout](results_layout.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T21:59:01.655933Z",
     "start_time": "2017-11-20T21:59:01.618926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>year</th>\n",
       "      <th>size</th>\n",
       "      <th>est</th>\n",
       "      <th>emp</th>\n",
       "      <th>sales</th>\n",
       "      <th>est_birth</th>\n",
       "      <th>est_expand</th>\n",
       "      <th>est_contract</th>\n",
       "      <th>est_death</th>\n",
       "      <th>emp_birth</th>\n",
       "      <th>emp_contract</th>\n",
       "      <th>emp_expand</th>\n",
       "      <th>emp_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>9999</td>\n",
       "      <td>218651</td>\n",
       "      <td>3002702</td>\n",
       "      <td>396076775</td>\n",
       "      <td>13780</td>\n",
       "      <td>19532</td>\n",
       "      <td>16581</td>\n",
       "      <td>26950</td>\n",
       "      <td>91969</td>\n",
       "      <td>106740</td>\n",
       "      <td>143443</td>\n",
       "      <td>192636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>38378</td>\n",
       "      <td>38378</td>\n",
       "      <td>4812488</td>\n",
       "      <td>3796</td>\n",
       "      <td>0</td>\n",
       "      <td>3713</td>\n",
       "      <td>5389</td>\n",
       "      <td>3796</td>\n",
       "      <td>8680</td>\n",
       "      <td>0</td>\n",
       "      <td>5389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>128572</td>\n",
       "      <td>495115</td>\n",
       "      <td>70877932</td>\n",
       "      <td>8368</td>\n",
       "      <td>10465</td>\n",
       "      <td>9343</td>\n",
       "      <td>18369</td>\n",
       "      <td>28409</td>\n",
       "      <td>29923</td>\n",
       "      <td>17843</td>\n",
       "      <td>65527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>47010</td>\n",
       "      <td>1188288</td>\n",
       "      <td>153653201</td>\n",
       "      <td>1505</td>\n",
       "      <td>8167</td>\n",
       "      <td>3228</td>\n",
       "      <td>3005</td>\n",
       "      <td>34370</td>\n",
       "      <td>34127</td>\n",
       "      <td>64657</td>\n",
       "      <td>69267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>100</td>\n",
       "      <td>4185</td>\n",
       "      <td>740391</td>\n",
       "      <td>103059933</td>\n",
       "      <td>102</td>\n",
       "      <td>808</td>\n",
       "      <td>265</td>\n",
       "      <td>164</td>\n",
       "      <td>18774</td>\n",
       "      <td>17667</td>\n",
       "      <td>37614</td>\n",
       "      <td>30896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WI</td>\n",
       "      <td>55</td>\n",
       "      <td>1998</td>\n",
       "      <td>500</td>\n",
       "      <td>506</td>\n",
       "      <td>540530</td>\n",
       "      <td>63673221</td>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>6620</td>\n",
       "      <td>16343</td>\n",
       "      <td>23329</td>\n",
       "      <td>21557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state state_code  year  size     est      emp      sales  est_birth  \\\n",
       "0    WI         55  1998  9999  218651  3002702  396076775      13780   \n",
       "1    WI         55  1998     1   38378    38378    4812488       3796   \n",
       "2    WI         55  1998     2  128572   495115   70877932       8368   \n",
       "3    WI         55  1998    10   47010  1188288  153653201       1505   \n",
       "4    WI         55  1998   100    4185   740391  103059933        102   \n",
       "5    WI         55  1998   500     506   540530   63673221          9   \n",
       "\n",
       "   est_expand  est_contract  est_death  emp_birth  emp_contract  emp_expand  \\\n",
       "0       19532         16581      26950      91969        106740      143443   \n",
       "1           0          3713       5389       3796          8680           0   \n",
       "2       10465          9343      18369      28409         29923       17843   \n",
       "3        8167          3228       3005      34370         34127       64657   \n",
       "4         808           265        164      18774         17667       37614   \n",
       "5          92            32         23       6620         16343       23329   \n",
       "\n",
       "   emp_death  \n",
       "0     192636  \n",
       "1       5389  \n",
       "2      65527  \n",
       "3      69267  \n",
       "4      30896  \n",
       "5      21557  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-20T21:58:57.651056Z",
     "start_time": "2017-11-20T21:58:56.552735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_state_year = '''\n",
    "SELECT *\n",
    "FROM `{table}`\n",
    "WHERE state = '{st}' and year = {y}\n",
    "'''.format(table=state_table_path, st='WI', y=1998)\n",
    "\n",
    "vars_total = ['est', 'emp', 'sales', 'est_birth', 'est_expand', 'est_contract', 'est_death', 'emp_birth', 'emp_contract', 'emp_expand', 'emp_death']\n",
    "query_agg = []\n",
    "for v in vars_total:\n",
    "    query_agg.append('  SUM(%s) as %s' % (v, v))\n",
    "query_agg = ',\\n'.join(query_agg)\n",
    "\n",
    "\n",
    "query_total = '''\n",
    "SELECT\n",
    "  state, state_code, year,\n",
    "  9999 as size,\n",
    "{q_agg}\n",
    "FROM state_year\n",
    "GROUP BY state, state_code, year\n",
    "'''.format(q_agg=query_agg)\n",
    "\n",
    "query = '''\n",
    "WITH state_year AS ({q_state_year})\n",
    "SELECT * FROM state_year\n",
    "UNION ALL\n",
    "({q_total})\n",
    "'''.format(q_state_year=query_state_year, q_total=query_total)\n",
    "\n",
    "df = pd.read_gbq(query, verbose=False, dialect='standard', project_id=client.project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emp == 0: what is this?\n",
    "\n",
    "Null employment: is employment_category also null?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Startup\" variable\n",
    "\n",
    "When firm with same ABI appears after a break, is it a startup?\n",
    "\n",
    "```\n",
    "Row\tabi\tyear\tfips\temp\tsales\tnaics\tstartup\temp_lag\tbirth\tdeath\tyear_preceding\tsize\temp_change\temp_lag0\tbirth0\tdeath0\t \n",
    "11\t612580\t2007\t9003\t50\t6950\t33351711\tnull\t50\tfalse\tfalse\t2006\t10\t0\t50\tfalse\tfalse\t \n",
    "12\t612580\t2012\t9003\t45\t6950\t33351711\tNew\t50\tfalse\tfalse\t2007\t10\tnull\tnull\tfalse\tfalse\t \n",
    "13\t612580\t2013\t9003\t45\t10615\t33351711\tnull\t45\tfalse\tfalse\t2012\t10\t0\t45\tfalse\tfalse\t \n",
    "\n",
    "20\t632026\t2000\t25017\t297\tnull\t33911203\tnull\t297\tfalse\tfalse\t1999\t100\t0\t297\tfalse\tfalse\t \n",
    "21\t632026\t2001\t25017\t275\tnull\t33911203\tnull\t297\tfalse\tfalse\t2000\t100\t-22\t297\tfalse\tfalse\t \n",
    "22\t632026\t2003\t25017\t170\tnull\t33451315\tExpStart\t275\tfalse\tfalse\t2001\t100\tnull\tnull\tfalse\tfalse\t \n",
    "23\t632026\t2004\t25017\t170\tnull\t33451315\tnull\t170\tfalse\tfalse\t2003\t100\t0\t170\tfalse\tfalse\t \n",
    "\n",
    "46\t929265\t2007\t9001\t60\t6600\t33399920\tnull\t60\tfalse\tfalse\t2006\t10\t0\t60\tfalse\tfalse\t \n",
    "47\t929265\t2012\t9001\t60\t12720\t33211912\tNew\t60\tfalse\tfalse\t2007\t10\tnull\tnull\tfalse\tfalse\t \n",
    "48\t929265\t2013\t9001\t60\t11054\t33211912\tnull\t60\tfalse\tfalse\t2012\t10\t0\t60\tfalse\tfalse\t \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
